//
//  main.m
//  Xcode 4 OpenCL Example
//
//  Created by Daniel Farrell on 24/03/2013.
//  Copyright (c) 2013 d. All rights reserved.
//

#import <Cocoa/Cocoa.h>

////////////////////////////////////////////////////////////////////////////////
#include <stdio.h>
#include <stdlib.h>

// This include pulls in everything you need to develop with OpenCL on OS X v10.7.
#include <OpenCL/opencl.h>

// Include the header file generated by Xcode.  This header file contains the
//  kernel block declaration.
#include "square_kernel.cl.h"
#include "sum_columns_kernel.cl.h"

// Hardcoded number of values to test, for convenience.
#define NUM_VALUES 1024

// Float comparison marcos (requires float.h)
#include <float.h>
#define fequal(a,b) (fabs((a) - (b)) < FLT_EPSILON)
#define fequalzero(a) (fabs(a) < FLT_EPSILON)

// A utility function that checks that our kernel execution performs the
// requested work over the entire range of data.
static int validate(cl_float* input, cl_float* output) {
    int i;
    for (i = 0; i < NUM_VALUES; i++) {
        
        // The kernel was supposed to square each value.
        if ( output[i] != (input[i] * input[i]) ) {
            fprintf(stdout, "Error: Element %d did not match expected output.\n", i);
            fprintf(stdout, "       Saw %1.4f, expected %1.4f\n", output[i],
                    input[i] * input[i]);
            fflush(stdout);
            return 0;
        }
    }
    return 1;
}

static int validate_column_sum(cl_float* input, cl_float* output) {
    int i,j;
    for (j=0; j<NUM_VALUES; j++) {
        float sum = 0;
        for (i = 0; i < NUM_VALUES; i++) {
            sum += input[i + NUM_VALUES*j];
        }
        
        // The kernel was supposed to sum along each column.
        if ( !fequal(output[j], sum)  ) {
            fprintf(stdout, "Error: Column The sum for column number %d did not match expected output.\n", j);
            fprintf(stdout, "       The kernel returned %1.4f, expected %1.4f\n", output[j], sum);
            fflush(stdout);
            return 0;
        }
    }
    return 1;
}

//int main (int argc, const char * argv[]) {
//    int i;
//    char name[128];
//    
//    // First, try to obtain a dispatch queue that can send work to the
//    // GPU in our system.                                                [2]
//    dispatch_queue_t queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_GPU,
//                                                       NULL);
//    
//    // In the event that our system does NOT have an OpenCL-compatible GPU,
//    // we can use the OpenCL CPU compute device instead.
//    if (queue == NULL) {
//        queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
//    }
//    
//    // This is not required, but let's print out the name of the device
//    // we are using to do work.  We could use the same function,
//    // clGetDeviceInfo, to obtain all manner of information about the device.
//    cl_device_id gpu = gcl_get_device_id_with_dispatch_queue(queue);
//    clGetDeviceInfo(gpu, CL_DEVICE_NAME, 128, name, NULL);
//    fprintf(stdout, "Created a dispatch queue using the %s\n", name);
//    
//    // Now we gin up some test data.  This is typically the case: you have some
//    // data in your application that you want to process with OpenCL.  This
//    // test_in buffer represents such data.  Normally, this would come from
//    // some REAL source, like a camera, a sensor, or some compiled collection
//    // of statistics -- it just depends on the problem you want to solve.
//    float* test_in = (float*)malloc(sizeof(cl_float) * NUM_VALUES);
//    for (i = 0; i < NUM_VALUES; i++) {
//        test_in[i] = (cl_float)i;
//    }
//    
//    // Once the computation using CL is done, we'll want to read the results
//    // back into our application's memory space.  Allocate some space for that.
//    float* test_out = (float*)malloc(sizeof(cl_float) * NUM_VALUES);
//    
//    // Our test kernel takes two parameters: an input float array and an
//    // output float array.  We can't send the application's buffers above, since
//    // our CL device operates on its own memory space.  Therefore, we allocate
//    // OpenCL memory for doing the work.  Notice that for the input array,
//    // we specify CL_MEM_COPY_HOST_PTR and provide the fake input data we
//    // created above.  This tells OpenCL to copy over our data into its memory
//    // space before it executes the kernel.                                   [3]
//    void* mem_in  = gcl_malloc(sizeof(cl_float) * NUM_VALUES, test_in,
//                               CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
//    
//    // The output array is not initalized; we're going to fill it up when
//    // we execute our kernel.                                                 [4]
//    void* mem_out = gcl_malloc(sizeof(cl_float) * NUM_VALUES, NULL,
//                               CL_MEM_WRITE_ONLY);
//    
//    // Dispatch your kernel block using one of the dispatch_ commands and the
//    // queue we created above.                                                [5]
//    
//    dispatch_sync(queue, ^{
//        
//        // Though we COULD pass NULL as the workgroup size, which would tell
//        // OpenCL to pick the one it thinks is best, we can also ask
//        // OpenCL for the suggested size, and pass it ourselves.              [6]
//        size_t wgs;
//        gcl_get_kernel_block_workgroup_info(square_kernel,
//                                            CL_KERNEL_WORK_GROUP_SIZE,
//                                            sizeof(wgs), &wgs, NULL);
//        
//        
//        printf("OpenCL determinded workgroup size is %d.\n", wgs);
//        
//        // The N-Dimensional Range over which we'd like to execute our
//        // kernel.  In our example case, we're operating on a 1D buffer, so
//        // it makes sense that our range is 1D.
//        cl_ndrange range = {
//            1,                     // The number of dimensions to use.
//            
//            {0, 0, 0},             // The offset in each dimension.  We want to
//            // process ALL of our data, so this is 0 for
//            // our test case.                          [7]
//            
//            {NUM_VALUES, 0, 0},    // The global range -- this is how many items
//            // IN TOTAL in each dimension you want to
//            // process.
//            
//            {wgs, 0, 0} // The local size of each workgroup.  This
//            // determines the number of workitems per
//            // workgroup.  It indirectly affects the
//            // number of workgroups, since the global
//            // size / local size yields the number of
//            // workgroups.  So in our test case, we will
//            // have NUM_VALUE / wgs workgroups.
//        };
//        // Calling the kernel is easy; you simply call it like a function,
//        // passing the ndrange as the first parameter, followed by the expected
//        // kernel parameters.  Note that we case the 'void*' here to the
//        // expected OpenCL types.  Remember -- if you use 'float' in your
//        // kernel, that's a 'cl_float' from the application's perspective.   [8]
//        
//        square_kernel(&range,(cl_float*)mem_in, (cl_float*)mem_out);
//        
//        // Getting data out of the device's memory space is also easy; we
//        // use gcl_memcpy.  In this case, we take the output computed by the
//        // kernel and copy it over to our application's memory space.        [9]
//        
//        gcl_memcpy(test_out, mem_out, sizeof(cl_float) * NUM_VALUES);
//        
//    });
//    
//    
//    // Now we can check to make sure our kernel really did what we asked
//    // it to:
//    
//    if ( validate(test_in, test_out)) {
//        fprintf(stdout, "All values were properly squared.\n");
//    }
//    
//    // Don't forget to free up the CL device's memory when you're done.      [10]
//    gcl_free(mem_in);
//    gcl_free(mem_out);
//    
//    // And the same goes for system memory, as usual.
//    free(test_in);
//    free(test_out);
//    
//    // Finally, release your queue just as you would any GCD queue.          [11]
//    dispatch_release(queue);
//}

int main (int argc, const char * argv[]) {
    
    // First, try to obtain a dispatch queue that can send work to the
    // GPU in our system.                                                [2]
    dispatch_queue_t queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU,
                                                       NULL);
    
    // In the event that our system does NOT have an OpenCL-compatible GPU,
    // we can use the OpenCL CPU compute device instead.
    if (queue == NULL) {
        queue = gcl_create_dispatch_queue(CL_DEVICE_TYPE_CPU, NULL);
    }
    
    // This is not required, but let's print out the name of the device
    // we are using to do work.  We could use the same function,
    // clGetDeviceInfo, to obtain all manner of information about the device.
    cl_device_id gpu = gcl_get_device_id_with_dispatch_queue(queue);
    char name[128];
    clGetDeviceInfo(gpu, CL_DEVICE_NAME, 128, name, NULL);
    fprintf(stdout, "Created a dispatch queue using the %s\n", name);
    
    // Now we gin up some test data.  This is typically the case: you have some
    // data in your application that you want to process with OpenCL.  This
    // test_in buffer represents such data.  Normally, this would come from
    // some REAL source, like a camera, a sensor, or some compiled collection
    // of statistics -- it just depends on the problem you want to solve.
    float* test_in = (float*)malloc(sizeof(cl_float) * NUM_VALUES * NUM_VALUES);
    int i,j;
    for (j = 0; j < NUM_VALUES; j++) {
        for (i = 0; i < NUM_VALUES; i++) {
            test_in[i + NUM_VALUES*j] = 1.0;
        }
    }
    
    // Once the computation using CL is done, we'll want to read the results
    // back into our application's memory space.  Allocate some space for that.
    float* test_out = (float*)malloc(sizeof(cl_float) * NUM_VALUES);
    
    // Our test kernel takes two parameters: an input float array and an
    // output float array.  We can't send the application's buffers above, since
    // our CL device operates on its own memory space.  Therefore, we allocate
    // OpenCL memory for doing the work.  Notice that for the input array,
    // we specify CL_MEM_COPY_HOST_PTR and provide the fake input data we
    // created above.  This tells OpenCL to copy over our data into its memory
    // space before it executes the kernel.                                   [3]
    void* mem_in  = gcl_malloc(sizeof(cl_float) * NUM_VALUES * NUM_VALUES, test_in,
                               CL_MEM_READ_ONLY | CL_MEM_COPY_HOST_PTR);
    
    // The output array is not initalized; we're going to fill it up when
    // we execute our kernel.                                                 [4]
    void* mem_out = gcl_malloc(sizeof(cl_float) * NUM_VALUES, NULL,
                               CL_MEM_WRITE_ONLY);
    
    // Dispatch your kernel block using one of the dispatch_ commands and the
    // queue we created above.                                                [5]
    
    dispatch_sync(queue, ^{
        
        // Though we COULD pass NULL as the workgroup size, which would tell
        // OpenCL to pick the one it thinks is best, we can also ask
        // OpenCL for the suggested size, and pass it ourselves.              [6]
        size_t wgs;
        gcl_get_kernel_block_workgroup_info(sum_columns_kernel,
                                            CL_KERNEL_WORK_GROUP_SIZE,
                                            sizeof(wgs), &wgs, NULL);
        
        
        printf("OpenCL determinded workgroup size is %zd.\n", wgs);
        
        // The N-Dimensional Range over which we'd like to execute our
        // kernel.  In our example case, we're operating on a 1D buffer, so
        // it makes sense that our range is 1D.
        cl_ndrange range = {
            1,                     // The number of dimensions to use.
            
            {0, 0, 0},             // The offset in each dimension.  We want to
            // process ALL of our data, so this is 0 for
            // our test case.                          [7]
            
            {NUM_VALUES, 0, 0},    // The global range -- this is how many items
            // IN TOTAL in each dimension you want to
            // process.
            
            {wgs, 0, 0} // The local size of each workgroup.  This
            // determines the number of workitems per
            // workgroup.  It indirectly affects the
            // number of workgroups, since the global
            // size / local size yields the number of
            // workgroups.  So in our test case, we will
            // have NUM_VALUE / wgs workgroups.
        };
        // Calling the kernel is easy; you simply call it like a function,
        // passing the ndrange as the first parameter, followed by the expected
        // kernel parameters.  Note that we case the 'void*' here to the
        // expected OpenCL types.  Remember -- if you use 'float' in your
        // kernel, that's a 'cl_float' from the application's perspective.   [8]
        int dims = NUM_VALUES;
        int i = 0;
        while (i < 1) { // <---- CHANGE THE COUNTER TO INCREASE SAMPLE SIZE
            sum_columns_kernel(&range,(cl_float*)mem_in, (cl_float*)mem_out, (cl_int)dims, (cl_int)dims);
            i++;
        }

        
        // Getting data out of the device's memory space is also easy; we
        // use gcl_memcpy.  In this case, we take the output computed by the
        // kernel and copy it over to our application's memory space.        [9]
        
        gcl_memcpy(test_out, mem_out, sizeof(cl_float) * NUM_VALUES);
        
    });
    
    
    // Now we can check to make sure our kernel really did what we asked
    // it to:
    
    if ( validate_column_sum(test_in, test_out)) {
        fprintf(stdout, "All columns were properly summated.\n");
    }
    
    // Don't forget to free up the CL device's memory when you're done.      [10]
    gcl_free(mem_in);
    gcl_free(mem_out);
    
    // And the same goes for system memory, as usual.
    free(test_in);
    free(test_out);
    
    // Finally, release your queue just as you would any GCD queue.          [11]
    dispatch_release(queue);
}
